{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AZR Model Trainer v2 — Google Colab\n",
    "\n",
    "**Neural network trainer with web UI, GPU acceleration, dataset catalog (136 datasets)**\n",
    "\n",
    "---\n",
    "\n",
    "### How to use:\n",
    "1. **Runtime → Change runtime type → GPU (T4)**\n",
    "2. Run all cells in order\n",
    "3. Click the **ngrok link** at the end to open the web interface\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: GPU not found! Go to Runtime -> Change runtime type -> GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone repository & install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone repo\n",
    "if not os.path.exists('/content/ai-neural-network-project'):\n",
    "    !git clone https://github.com/Slavikpro557/ai-neural-network-project.git\n",
    "else:\n",
    "    print('Repo already cloned, pulling latest...')\n",
    "    !cd /content/ai-neural-network-project && git pull\n",
    "\n",
    "# Install dependencies (torch is already installed on Colab)\n",
    "!pip install -q fastapi uvicorn python-multipart pydantic numpy psutil PyMuPDF pyngrok\n",
    "\n",
    "print('\\nDone!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup ngrok tunnel\n",
    "\n",
    "ngrok creates a public URL to access the server running on Colab.\n",
    "\n",
    "**Get a free token at https://ngrok.com (sign up → Your Authtoken)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your ngrok authtoken here (free at https://ngrok.com)\n",
    "NGROK_TOKEN = ''  # <-- paste your token inside the quotes\n",
    "\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "if NGROK_TOKEN:\n",
    "    ngrok.set_auth_token(NGROK_TOKEN)\n",
    "    print('ngrok token set!')\n",
    "else:\n",
    "    print('WARNING: No ngrok token. Get one free at https://ngrok.com')\n",
    "    print('Without token the tunnel may not work or will be rate-limited.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start AZR Trainer server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from pyngrok import ngrok\n",
    "\n",
    "os.chdir('/content/ai-neural-network-project')\n",
    "\n",
    "# Kill any existing server\n",
    "!kill $(lsof -t -i:8000) 2>/dev/null; true\n",
    "time.sleep(1)\n",
    "\n",
    "# Start server in background\n",
    "server_process = subprocess.Popen(\n",
    "    ['python', 'server_with_datasets.py'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    cwd='/content/ai-neural-network-project'\n",
    ")\n",
    "\n",
    "# Wait for server to start\n",
    "print('Starting server...')\n",
    "time.sleep(5)\n",
    "\n",
    "# Check if server started\n",
    "if server_process.poll() is None:\n",
    "    print('Server is running!')\n",
    "else:\n",
    "    print('ERROR: Server failed to start. Check logs below:')\n",
    "    print(server_process.stdout.read().decode('utf-8', errors='replace'))\n",
    "\n",
    "# Open ngrok tunnel\n",
    "try:\n",
    "    # Close existing tunnels\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    for t in tunnels:\n",
    "        ngrok.disconnect(t.public_url)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "public_url = ngrok.connect(8000)\n",
    "\n",
    "print()\n",
    "print('=' * 60)\n",
    "print(f'  AZR Model Trainer is running!')\n",
    "print(f'  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')\n",
    "print(f'')\n",
    "print(f'  Open this link:')\n",
    "print(f'  {public_url}')\n",
    "print(f'')\n",
    "print(f'  (keep this cell running!)')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Server logs (optional)\n",
    "Run this cell to see server output if something goes wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last server logs\n",
    "import subprocess\n",
    "result = subprocess.run(['tail', '-30', '/proc/' + str(server_process.pid) + '/fd/1'],\n",
    "                       capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    # Alternative: read from process\n",
    "    print('Server PID:', server_process.pid)\n",
    "    print('Status:', 'Running' if server_process.poll() is None else 'Stopped')\n",
    "else:\n",
    "    print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stop server (when done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to stop everything\n",
    "ngrok.kill()\n",
    "server_process.terminate()\n",
    "print('Server stopped. Tunnel closed.')"
   ]
  }
 ]
}