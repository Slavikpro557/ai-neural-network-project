# AZR Model Trainer v2

### [English version (EN)](README.md)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Slavikpro557/ai-neural-network-project/blob/main/AZR_Trainer_Colab.ipynb)

Веб-система для создания, обучения и анализа нейронных языковых моделей методом **Absolute Zero Reasoner (AZR)** с **REINFORCE** self-play для непрерывного самообучения.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

---

## Возможности

- **Кастомная трансформерная архитектура** — создавайте модели с любой конфигурацией (слои, головы, размер эмбеддингов)
- **AZR Self-Play обучение** — модель улучшает себя через самоигру с REINFORCE policy gradient
- **6-компонентная система наград** — разнообразие, когерентность, штраф за повторы, длина, богатство словаря, естественность биграмм
- **Каталог датасетов** — 110 встроенных датасетов (русская и английская литература, фантастика, детективы, поэзия, код, философия и др.)
- **Поиск по HuggingFace** — находите и скачивайте датасеты прямо из HuggingFace
- **Мульти-датасетное обучение** — прикрепляйте несколько датасетов к одной модели
- **Мониторинг в реальном времени** — графики loss, лента итераций, умный анализ изменений
- **GPU ускорение** — автоматическое определение CUDA, установка GPU одним кликом на Windows
- **Google Colab** — запуск на бесплатном Tesla T4 GPU одним кликом
- **Двуязычный интерфейс** — полный RU/EN интерфейс с переключателем языка
- **Сравнение моделей** — сравнение разных моделей бок о бок
- **Экспорт** — скачивание обученных моделей как .pt файлы

## Быстрый старт

### Вариант 1: Google Colab (рекомендуется, бесплатный GPU)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Slavikpro557/ai-neural-network-project/blob/main/AZR_Trainer_Colab.ipynb)

1. Нажмите на значок выше
2. В Colab: **Runtime > Change runtime type > GPU (T4)**
3. Запустите все ячейки
4. Перейдите по ссылке ngrok для открытия веб-интерфейса

### Вариант 2: Локальная установка

```bash
git clone https://github.com/Slavikpro557/ai-neural-network-project.git
cd ai-neural-network-project
pip install -r requirements.txt
python server_with_datasets.py
```

Откройте http://localhost:8000 в браузере.

### Вариант 3: Windows в один клик

Запустите `start.bat` — он установит зависимости и запустит сервер автоматически.

Для GPU: сначала запустите `install_gpu.bat`, затем `start_gpu.bat`.

## Как это работает

### Обучение AZR (Absolute Zero Reasoner)

1. **Обучение с учителем** на текстовых данных (книги, статьи, код) — модель учит паттерны языка
2. **Self-play генерация** — модель генерирует примеры текста
3. **Оценка наградой** — 6-компонентная функция награды оценивает каждый пример:
   - Разнообразие токенов
   - Когерентность (вероятность биграмм)
   - Штраф за повторения
   - Оценка длины
   - Богатство словаря
   - Естественность биграмм
4. **REINFORCE обновление** — policy gradient корректирует веса модели (0.5% RL + supervised loss)
5. **Валидация** — разделение 90/10 train/val с логированием val_loss
6. **Повтор** — цикл продолжается, модель постоянно улучшается

### Архитектура

- Кастомный **Transformer** с настраиваемой глубиной, шириной и числом голов внимания
- **BPE-токенизатор**, обучаемый на ваших данных
- **Чекпоинтинг** каждые N итераций с возможностью возобновления
- **DataLoader** с `pin_memory=True` для ускорения GPU

## Каталог датасетов

110 встроенных датасетов в 16 категориях:

| Категория | Кол-во | Примеры |
|-----------|--------|---------|
| Классика (EN) | 22 | Алиса в стране чудес, Франкенштейн, Гордость и предубеждение |
| Классика (RU) | 13 | Анна Каренина, Война и мир, Идиот, Мёртвые души |
| Детективы | 4 | Шерлок Холмс, Собака Баскервилей |
| Фантастика | 9 | Машина времени, Война миров, Франкенштейн |
| Поэзия | 9 | Сонеты Шекспира, Евгений Онегин, Листья травы |
| Философия | 8 | Государство, Размышления, По ту сторону добра и зла |
| Сказки | 8 | Сказки Гримм, Андерсен, 1001 ночь |
| + ещё 9 | 37 | Ужасы, Приключения, Пьесы, Код, Наука и др. |

Все датасеты — общественное достояние или свободные лицензии. Также можно загружать свои файлы `.txt`, `.csv`, `.json`, `.jsonl`, `.pdf`.

## Структура проекта

```
ai-neural-network-project/
├── server_with_datasets.py   # Основной сервер (FastAPI)
├── server.py                 # Старый сервер
├── model.py                  # Архитектура трансформера
├── azr_trainer.py            # AZR тренер (базовый)
├── azr_trainer_resume.py     # AZR тренер с возобновлением
├── reward_model.py           # 6-компонентная система наград
├── dataset_catalog.py        # 110 встроенных датасетов
├── dataset_manager.py        # Управление мульти-датасетами
├── tokenizer.py              # BPE токенизатор
├── AZR_Trainer_Colab.ipynb   # Ноутбук для Google Colab
├── requirements.txt          # Зависимости
├── start.bat                 # Запуск на Windows
├── templates/
│   └── index_complete.html   # Веб-интерфейс (RU/EN)
├── models/                   # Сохранённые модели
├── books/                    # Датасеты
└── checkpoints/              # Чекпоинты обучения
```

## Параметры модели

| Параметр | Описание | Рекомендуемые значения |
|----------|----------|------------------------|
| vocab_size | Размер словаря | 5 000 — 15 000 |
| d_model | Размерность эмбеддингов | 128 — 512 |
| num_layers | Кол-во слоёв трансформера | 4 — 12 |
| num_heads | Головы внимания | 4 — 16 |
| d_ff | Размер feed-forward | d_model x 4 |
| max_seq_len | Макс. длина последовательности | 128 — 512 |

## Требования

- Python 3.8+
- PyTorch 2.0+
- 4 ГБ+ RAM (рекомендуется 8 ГБ+)
- GPU опционально (NVIDIA с CUDA для ускорения)

## Решение проблем

| Проблема | Решение |
|----------|---------|
| CUDA out of memory | Уменьшите batch_size (16 → 8 → 4) или размер модели |
| Медленное обучение | Установите PyTorch с CUDA, уменьшите max_seq_len |
| Плохая генерация | Обучайте дольше, используйте больше данных, увеличьте модель |
| Нечитаемый текст датасета | Перекачайте из каталога (авто-определение кодировки исправлено) |

## Лицензия

Свободное использование для личных и коммерческих проектов.
