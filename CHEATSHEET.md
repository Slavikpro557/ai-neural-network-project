# ðŸ“‹ Ð¨Ð¿Ð°Ñ€Ð³Ð°Ð»ÐºÐ° AZR Model Trainer

## âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹

### Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°
```bash
pip install -r requirements.txt
```

### Ð—Ð°Ð¿ÑƒÑÐº ÑÐµÑ€Ð²ÐµÑ€Ð°
```bash
python server.py
# ÐžÑ‚ÐºÑ€Ð¾Ð¹Ñ‚Ðµ http://localhost:8000
```

### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
```bash
python test_model.py
```

### CLI Ð´ÐµÐ¼Ð¾
```bash
python cli_demo.py
```

---

## ðŸ”§ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸

| ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ | ÐœÐ°Ð»Ð°Ñ | Ð¡Ñ€ÐµÐ´Ð½ÑÑ | Ð‘Ð¾Ð»ÑŒÑˆÐ°Ñ |
|----------|-------|---------|---------|
| **vocab_size** | 5000 | 8000 | 15000 |
| **d_model** | 128 | 256-384 | 512-768 |
| **num_layers** | 4 | 6-8 | 10-16 |
| **num_heads** | 4 | 8 | 12-16 |
| **d_ff** | 512 | 1024-1536 | 2048-3072 |
| **max_seq_len** | 128 | 256 | 512-1024 |
| **ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹** | ~1-5M | ~10-30M | ~50-200M |
| **Ð’Ñ€ÐµÐ¼Ñ (10K iter)** | 5-10 Ð¼Ð¸Ð½ | 20-40 Ð¼Ð¸Ð½ | 1-3 Ñ‡Ð°ÑÐ° |

---

## ðŸ“Š Ð“Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

### Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ñ‚ÐµÑÑ‚
```
Max Iterations: 1,000
Batch Size: 8
Learning Rate: 0.001
```

### Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
```
Max Iterations: 50,000
Batch Size: 16
Learning Rate: 0.0003
Save Every: 1,000
```

### ÐŸÑ€Ð¾Ð´Ð°ÐºÑˆÐ½
```
Max Iterations: 500,000+
Batch Size: 32
Learning Rate: 0.0001
Save Every: 5,000
```

---

## ðŸŽ¯ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸

### Ð¢Ð¾Ñ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
```json
{
  "temperature": 0.5,
  "top_k": 20,
  "max_length": 50
}
```

### Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ
```json
{
  "temperature": 0.8,
  "top_k": 40,
  "max_length": 100
}
```

### ÐšÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð°Ñ
```json
{
  "temperature": 1.2,
  "top_k": 50,
  "max_length": 200
}
```

---

## ðŸ“ Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ñ„Ð°Ð¹Ð»Ð¾Ð²

```
Ð´Ð»Ñ Ð¸Ð¸/
â”œâ”€â”€ model.py              # ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°
â”œâ”€â”€ tokenizer.py          # Ð¢Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ñ
â”œâ”€â”€ azr_trainer.py        # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
â”œâ”€â”€ server.py             # API ÑÐµÑ€Ð²ÐµÑ€
â”œâ”€â”€ templates/index.html  # UI
â”œâ”€â”€ models/               # Ð’Ð°ÑˆÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
â”œâ”€â”€ books/                # Ð’Ð°ÑˆÐ¸ Ñ‚ÐµÐºÑÑ‚Ñ‹
â””â”€â”€ checkpoints/          # Ð§ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚Ñ‹
```

---

## ðŸ Python API

### Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
```python
from model import CustomTransformerLM

model = CustomTransformerLM(
    vocab_size=8000,
    d_model=256,
    num_layers=6,
    num_heads=8,
    d_ff=1024,
    max_seq_len=256
)
```

### Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ‚Ð¾Ñ€
```python
from tokenizer import SimpleTokenizer

tokenizer = SimpleTokenizer(vocab_size=8000)
tokenizer.train(texts)
tokenizer.save("tokenizer.pkl")
```

### ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ
```python
from azr_trainer import AZRTrainer

trainer = AZRTrainer(model, tokenizer)
trainer.train_continuous(
    texts=texts,
    max_iterations=10000,
    batch_size=16,
    lr=3e-4
)
```

### Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
```python
import torch

prompt = "Ð˜ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚"
tokens = tokenizer.encode(prompt)
idx = torch.tensor([tokens])

generated = model.generate(
    idx, 
    max_new_tokens=50,
    temperature=0.8,
    top_k=40
)

text = tokenizer.decode(generated[0].tolist())
print(text)
```

---

## ðŸŒ REST API

### Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
```bash
curl -X POST http://localhost:8000/create_model \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my_model",
    "vocab_size": 8000,
    "d_model": 256,
    "num_layers": 6,
    "num_heads": 8,
    "d_ff": 1024,
    "max_seq_len": 256
  }'
```

### ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
```bash
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "my_model",
    "book_file": "book.txt",
    "max_iterations": 10000,
    "batch_size": 16,
    "learning_rate": 0.0003,
    "save_every": 1000
  }'
```

### Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
```bash
curl http://localhost:8000/training_status
```

### Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "my_model",
    "prompt": "Ð˜ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚",
    "max_length": 100,
    "temperature": 0.8,
    "top_k": 40
  }'
```

---

## ðŸ” Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼

### Loss Ð½Ðµ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ°ÐµÑ‚ÑÑ
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ learning rate (0.0001)
- âœ… Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…
- âœ… Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ batch size

### Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐµÑ‚ÑÑ
- âœ… Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ temperature (>1.0)
- âœ… Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ top_k (50-100)
- âœ… Ð‘Ð¾Ð»ÑŒÑˆÐµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
- âœ… Ð Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½ÐµÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ

### Out of memory
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ batch_size (8 â†’ 4 â†’ 2)
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ max_seq_len
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ d_model
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ num_layers

### ÐœÐµÐ´Ð»ÐµÐ½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ (CPU)
- âœ… Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ PyTorch Ñ CUDA
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- âœ… Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ max_iterations Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°

---

## ðŸ’¡ Ð¡Ð¾Ð²ÐµÑ‚Ñ‹ Ð¸ Ñ‚Ñ€ÑŽÐºÐ¸

### Ð‘Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð¿Ñ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
```python
# ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²
d_model=64, num_layers=2, max_iterations=500
```

### Ð›ÑƒÑ‡ÑˆÐµÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾
```python
# Ð‘Ð¾Ð»ÑŒÑˆÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ… + Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹
max_iterations=100000+, diverse_data=True
```

### Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
```python
# Ð£Ð·ÐºÐ°Ñ Ñ‚ÐµÐ¼Ð° + Ð¼Ð½Ð¾Ð³Ð¾ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹
specific_domain=True, max_iterations=50000
```

### Transfer Learning
```python
# Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±Ñ‰Ð¸Ð¹ ÐºÐ¾Ñ€Ð¿ÑƒÑ, Ð¿Ð¾Ñ‚Ð¾Ð¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
1. Train on general text (50K)
2. Fine-tune on specific (10K, lr=1e-4)
```

---

## ðŸŽ¨ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð²

### Ð”Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸ÐºÐ¸
```
"Ð’ ÑÐ²ÐµÑ‚ÑÐºÐ¾Ð¼ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ðµ"
"ÐžÐ´Ð½Ð°Ð¶Ð´Ñ‹ Ð² Ñ…Ð¾Ð»Ð¾Ð´Ð½Ñ‹Ð¹ Ð·Ð¸Ð¼Ð½Ð¸Ð¹ Ð²ÐµÑ‡ÐµÑ€"
"ÐšÐ½ÑÐ·ÑŒ Ð·Ð°Ð´ÑƒÐ¼Ð°Ð»ÑÑ Ð¾"
```

### Ð”Ð»Ñ sci-fi
```
"ÐšÐ¾ÑÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ñ€Ð°Ð±Ð»ÑŒ Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð¶Ð°Ð»ÑÑ Ðº"
"Ð’ Ð´Ð°Ð»Ñ‘ÐºÐ¾Ð¼ Ð±ÑƒÐ´ÑƒÑ‰ÐµÐ¼ Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÑ‚Ð²Ð¾"
"Ð˜ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ Ð¾ÑÐ¾Ð·Ð½Ð°Ð»"
```

### Ð”Ð»Ñ Ð½Ð°ÑƒÐºÐ¸
```
"ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ ÑÐ¾Ð±Ð¾Ð¹"
"ÐšÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ñ Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐ° Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚"
"Ð­ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð», Ñ‡Ñ‚Ð¾"
```

### Ð”Ð»Ñ ÐºÐ¾Ð´Ð°
```
"def calculate_"
"class DataProcessor:"
"import numpy as np"
```

---

## ðŸ“ˆ Ð¦ÐµÐ»ÐµÐ²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸

### ÐŸÐ¾ÑÐ»Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
| Ð˜Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹ | Loss | Quality | Use Case |
|----------|------|---------|----------|
| 1K | 5-6 | ÐžÑ‡ÐµÐ½ÑŒ Ð½Ð¸Ð·ÐºÐ¾Ðµ | Ð¢ÐµÑÑ‚ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ |
| 10K | 3-4 | ÐÐ¸Ð·ÐºÐ¾Ðµ | Ð”ÐµÐ¼Ð¾ |
| 50K | 2-3 | Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ | Ð­ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ñ‹ |
| 100K | 1.5-2.5 | Ð¥Ð¾Ñ€Ð¾ÑˆÐµÐµ | ÐŸÑ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿Ñ‹ |
| 500K+ | 1-1.5 | ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ | ÐŸÑ€Ð¾Ð´Ð°ÐºÑˆÐ½ |

---

## ðŸš€ Workflow

### Ð¢Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ

1. **Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ** (30 ÑÐµÐº)
2. **Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ** (1 Ð¼Ð¸Ð½)
3. **ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ** (click)
4. **â˜• ÐŸÐµÑ€ÐµÑ€Ñ‹Ð²** (10 Ð¼Ð¸Ð½ - Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°ÑÐ¾Ð²)
5. **ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ** (1 Ð¼Ð¸Ð½)
6. **Ð•ÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ â†’ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ**
7. **Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ**
8. **Profit! ðŸŽ‰**

---

## ðŸ”¥ Ð“Ð¾Ñ€ÑÑ‡Ð¸Ðµ ÐºÐ»Ð°Ð²Ð¸ÑˆÐ¸

Ð’ Ð²ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐµ (Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÐµÑ‚ÑÑ):
- `Ctrl+N` - ÐÐ¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
- `Ctrl+U` - Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÐºÐ½Ð¸Ð³Ñƒ
- `Ctrl+T` - ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
- `Ctrl+G` - Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
- `Ctrl+S` - Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ

---

## ðŸ“ž Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ

### Ð“Ð´Ðµ Ð¸ÑÐºÐ°Ñ‚ÑŒ
1. `README.md` - ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ðµ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾
2. `QUICKSTART.md` - Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚
3. `ARCHITECTURE.md` - ÐšÐ°Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
4. `EXAMPLES.md` - ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹
5. `FEATURES.md` - Ð’ÑÐµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸

### Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹
```bash
# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Python
python --version

# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ PyTorch
python -c "import torch; print(torch.__version__)"

# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ CUDA
python -c "import torch; print(torch.cuda.is_available())"

# Ð¢ÐµÑÑ‚ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
python test_model.py

# CLI Ð´ÐµÐ¼Ð¾
python cli_demo.py
```

---

## ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°

### Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
```python
torch.save(model.state_dict(), "model.pt")
tokenizer.save("tokenizer.pkl")
```

### Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
```python
model.load_state_dict(torch.load("model.pt"))
tokenizer = SimpleTokenizer.load("tokenizer.pkl")
```

### Ð§ÐµÑ€ÐµÐ· Ð²ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ
- Ð’ÐºÐ»Ð°Ð´ÐºÐ° "ÐœÐ¾Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸"
- ÐšÐ½Ð¾Ð¿ÐºÐ° "Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"

---

## ðŸŽ¯ Ð§ÐµÐºÐ»Ð¸ÑÑ‚ Ð¿ÐµÑ€ÐµÐ´ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐ½

- [ ] ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¾ >100K Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹
- [ ] Loss <2.0
- [ ] ÐŸÑ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
- [ ] Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚Ñ‹
- [ ] Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ
- [ ] ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸
- [ ] ÐŸÑ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð° Ð½Ð° edge cases

---

**Ð£ÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ! ðŸ§ âœ¨**

*Ð Ð°ÑÐ¿ÐµÑ‡Ð°Ñ‚Ð°Ð¹Ñ‚Ðµ ÑÑ‚Ñƒ ÑˆÐ¿Ð°Ñ€Ð³Ð°Ð»ÐºÑƒ Ð¸ Ð´ÐµÑ€Ð¶Ð¸Ñ‚Ðµ Ñ€ÑÐ´Ð¾Ð¼!*
